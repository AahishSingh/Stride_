{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc289b-4623-40af-904d-a6184d8b733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from PIL.ImageQt import ImageQt\n",
    "from PyQt5 import QtCore, QtGui, QtWidgets, uic\n",
    "from PyQt5.QtWidgets import QWidget, QLabel\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069cf160-e884-4aba-84db-a03a09984a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save data to pickle file\n",
    "def save_pickle(filename, data):\n",
    "    with open(filename, \"wb\") as fo:\n",
    "        pickle.dump(data, fo, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Function to load data from pickle file\n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as fo:\n",
    "        return pickle.load(fo)\n",
    "\n",
    "# Main application class\n",
    "class GaitDemo(QtWidgets.QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load the UI file\n",
    "        uic.loadUi(\"stridesentinelUI.ui\", self)\n",
    "\n",
    "        # Set up UI elements\n",
    "        self.showFullScreen()\n",
    "\n",
    "        # Initialize camera\n",
    "        self.capture = cv2.VideoCapture(0)  # Adjust camera index if necessary\n",
    "        if not self.capture.isOpened():\n",
    "            print(\"Error: Could not open camera.\")\n",
    "            sys.exit()\n",
    "\n",
    "        # Initialize variables\n",
    "        self.currentFrame = np.array([])\n",
    "        self.firstFrame = None\n",
    "        self.register_state = False\n",
    "        self.recognition_state = False\n",
    "        self.save_on = False\n",
    "        self.gei_fix_num = 20\n",
    "\n",
    "        # Connect UI buttons to methods\n",
    "        self.save_gei.clicked.connect(self.save_gei_f)\n",
    "        self.register_2.clicked.connect(self.register_show)\n",
    "        self.recognize.clicked.connect(self.recognition_show)\n",
    "        self.updater.clicked.connect(self.update_bk)\n",
    "\n",
    "        # Load dataset or initialize if it doesn't exist\n",
    "        self.load_dataset()\n",
    "\n",
    "        # Setup timer for video stream\n",
    "        self._timer = QtCore.QTimer(self)\n",
    "        self._timer.timeout.connect(self.play)\n",
    "        self._timer.start(27)  # Adjust timing as needed for your camera\n",
    "\n",
    "        # Show the main window\n",
    "        self.show()\n",
    "\n",
    "    # Method to handle saving GEI\n",
    "    def save_gei_f(self):\n",
    "        self.save_on = True\n",
    "        self.state_print.setPlainText('Saving!')\n",
    "\n",
    "    # Method to handle registering\n",
    "    def register_show(self):\n",
    "        self.register_state = True\n",
    "        self.recognition_state = False\n",
    "        self.state_print.setPlainText('Register!')\n",
    "        self.gei_current = np.zeros((128, 88), np.single)\n",
    "        self.numInGEI = 0\n",
    "\n",
    "    # Method to load dataset from pickle file or initialize if absent\n",
    "    def load_dataset(self):\n",
    "        self.data_path = './GaitData.pkl'\n",
    "        if QtCore.QFile.exists(self.data_path):\n",
    "            dic = load_pickle(self.data_path)\n",
    "            self.num = dic['num']\n",
    "            self.gei = dic['gei']\n",
    "            self.name = dic['name']\n",
    "        else:\n",
    "            self.num = 0\n",
    "            self.gei = np.zeros([100, 128, 88], np.uint8)\n",
    "            self.name = []\n",
    "            dic = {'num': self.num, 'gei': self.gei, 'name': self.name}\n",
    "            save_pickle(self.data_path, dic)\n",
    "\n",
    "        self.id_num.setPlainText('%d' % self.num)\n",
    "        self.state_print.setPlainText('Running!')\n",
    "\n",
    "    # Method to handle video stream processing\n",
    "    def play(self):\n",
    "        try:\n",
    "            ret, frame = self.capture.read()\n",
    "            if not ret:\n",
    "                print(\"STRIDESENTINEL by ml mavericks.\")\n",
    "                return\n",
    "\n",
    "            frame = cv2.resize(frame, (512, 384))\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "            if self.firstFrame is None:\n",
    "                self.firstFrame = gray\n",
    "\n",
    "            frameDelta = cv2.absdiff(self.firstFrame, gray)\n",
    "            thresh = cv2.threshold(frameDelta, 50, 255, cv2.THRESH_BINARY)[1]\n",
    "            self.FrameForUpdate = gray\n",
    "            thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "            (cnts, _) = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            thresh = np.array(thresh)\n",
    "            max_rec = 0\n",
    "\n",
    "            for c in cnts:\n",
    "                if cv2.contourArea(c) < 500:\n",
    "                    continue\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "                if w > 25 and h > 50:\n",
    "                    if max_rec < w * h:\n",
    "                        max_rec = w * h\n",
    "                        (x_max, y_max, w_max, h_max) = cv2.boundingRect(c)\n",
    "\n",
    "            if max_rec > 0:\n",
    "                cv2.rectangle(frame, (x_max, y_max), (x_max + w_max, y_max + h_max), (0, 255, 0), 2)\n",
    "                if x_max > 20:\n",
    "                    if self.register_state or self.recognition_state:\n",
    "                        nim = np.zeros([thresh.shape[0] + 10, thresh.shape[1] + 10], np.single)\n",
    "                        nim[y_max + 5:(y_max + h_max + 5), x_max + 5:(x_max + w_max + 5)] = thresh[y_max:(y_max + h_max), x_max:(x_max + w_max)]\n",
    "                        offsetX = 20\n",
    "                        ty, tx = (nim > 100).nonzero()\n",
    "                        sy, ey = ty.min(), ty.max() + 1\n",
    "                        sx, ex = tx.min(), tx.max() + 1\n",
    "                        h = ey - sy\n",
    "                        w = ex - sx\n",
    "\n",
    "                        if h > w:\n",
    "                            cx = int(tx.mean())\n",
    "                            cenX = h / 2\n",
    "                            start_w = int(cenX - (cx - sx))\n",
    "                            if max(cx - sx, ex - cx) < cenX:\n",
    "                                start_w = int(cenX - (cx - sx))  # Ensure integer\n",
    "                            \n",
    "                            tim = np.zeros((h, h), np.single)\n",
    "                            tim[:, int(start_w):int(start_w + w)] = nim[int(sy):int(ey), int(sx):int(ex)]  # Ensure all indices are integers\n",
    "\n",
    "                            rim = Image.fromarray(np.uint8(tim)).resize((128, 128), resample=Image.LANCZOS)\n",
    "                            tim = np.array(rim)[:, int(offsetX):int(offsetX + 88)]  # Ensure all indices are integers\n",
    "\n",
    "                            if self.numInGEI < self.gei_fix_num:\n",
    "                                self.gei_current += tim\n",
    "                            self.numInGEI += 1\n",
    "\n",
    "                        if self.numInGEI > self.gei_fix_num:\n",
    "                            if self.save_on:\n",
    "                                self.gei[self.num, :, :] = self.gei_current / self.gei_fix_num\n",
    "                                Image.fromarray(np.uint8(self.gei_current / self.gei_fix_num)).save('./gei/gei%02d%s.jpg' % (self.num, self.id_name.toPlainText()))\n",
    "                                self.name.append(self.id_name.toPlainText())\n",
    "                                self.num += 1\n",
    "                                self.id_num.setPlainText('%d' % self.num)\n",
    "                                dic = {'num': self.num, 'gei': self.gei, 'name': self.name}\n",
    "                                save_pickle(self.data_path, dic)\n",
    "                                self.save_on = False\n",
    "                                self.state_print.setPlainText('Saved!')\n",
    "                            elif self.recognition_state:\n",
    "                                self.gei_query = self.gei_current / (self.gei_fix_num)\n",
    "                                score = np.zeros(self.num)\n",
    "                                self.gei_to_com = np.zeros([128, 88], np.single)\n",
    "                                for q in range(self.num):\n",
    "                                    self.gei_to_com = self.gei[q, :, :]\n",
    "                                    score[q] = np.exp(-(((self.gei_query[:] - self.gei_to_com[:]) / (128 * 88)) ** 2).sum())\n",
    "\n",
    "                                if score.size == 0:\n",
    "                                    print(\"Error: The score array is empty.\")\n",
    "                                    return\n",
    "\n",
    "                                q_id = score.argmax()\n",
    "                                if True:\n",
    "                                    id_rec = '%s' % self.name[q_id]\n",
    "                                    cv2.putText(frame, id_rec, (x_max + 20, y_max + 20), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1.0, thickness=2, color=(0, 0, 255))\n",
    "            else:\n",
    "                self.gei_current = np.zeros((128, 88), np.single)\n",
    "                self.numInGEI = 0\n",
    "\n",
    "            self.currentFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            self.seg = np.repeat(thresh[:, :, np.newaxis], 3, axis=2)\n",
    "            self.seg[:, :, 0] = 0\n",
    "            self.seg[:, :, 2] = 0\n",
    "            self.display_video_stream()\n",
    "            self.display_segmentation_stream()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "    # Method to display video stream on label\n",
    "    def display_video_stream(self):\n",
    "        qimage = QtGui.QImage(self.currentFrame, self.currentFrame.shape[1], self.currentFrame.shape[0], QtGui.QImage.Format_RGB888)\n",
    "        pix = QtGui.QPixmap.fromImage(qimage)\n",
    "        self.video_label.setPixmap(pix)\n",
    "\n",
    "    # Method to display segmentation stream on label\n",
    "    def display_segmentation_stream(self):\n",
    "        seg_frame = QtGui.QImage(self.seg, self.seg.shape[1], self.seg.shape[0], QtGui.QImage.Format_RGB888)\n",
    "        pix = QtGui.QPixmap.fromImage(seg_frame)\n",
    "        self.seg_label.setPixmap(pix)\n",
    "\n",
    "    # Method to update background frame\n",
    "    def update_bk(self):\n",
    "        self.firstFrame = self.FrameForUpdate\n",
    "\n",
    "    # Method to handle recognition\n",
    "    def recognition_show(self):\n",
    "        self.recognition_state = True\n",
    "        self.register_state = False\n",
    "        self.state_print.setPlainText('Recognize!')\n",
    "\n",
    "    # Override closeEvent to properly release resources\n",
    "    def closeEvent(self, event):\n",
    "        self.capture.release()  # Release the camera\n",
    "        event.accept()\n",
    "\n",
    "# Main function to run the application\n",
    "if __name__ == \"__main__\":\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    window = GaitDemo()\n",
    "    sys.exit(app.exec_())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
